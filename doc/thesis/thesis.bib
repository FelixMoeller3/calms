// TODO: Remove the sources that were in the template
@inproceedings{chandrasekaran2020exploring,
  title={Exploring connections between active learning and model extraction},
  author={Chandrasekaran, Varun and Chaudhuri, Kamalika and Giacomelli, Irene and Jha, Somesh and Yan, Songbai},
  booktitle={29th USENIX Security Symposium (USENIX Security 20)},
  pages={1309--1326},
  year={2020}
}

@inproceedings{pal2020activethief,
  title={Activethief: Model extraction using active learning and unannotated public data},
  author={Pal, Soham and Gupta, Yash and Shukla, Aditya and Kanade, Aditya and Shevade, Shirish and Ganapathy, Vinod},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={01},
  pages={865--872},
  year={2020}
}

@article{sener2017active,
  title={Active learning for convolutional neural networks: A core-set approach},
  author={Sener, Ozan and Savarese, Silvio},
  journal={arXiv preprint arXiv:1708.00489},
  year={2017}
}

@inproceedings{kim2021task,
  title={Task-aware variational adversarial active learning},
  author={Kim, Kwanyoung and Park, Dongwon and Kim, Kwang In and Chun, Se Young},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8166--8175},
  year={2021}
}

@article{mundt2020wholistic,
  title={A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning},
  author={Mundt, Martin and Hong, Yong Won and Pliushch, Iuliia and Ramesh, Visvanathan},
  journal={arXiv preprint arXiv:2009.01797},
  year={2020}
}

@inproceedings{juuti2019prada,
  title={PRADA: protecting against DNN model stealing attacks},
  author={Juuti, Mika and Szyller, Sebastian and Marchal, Samuel and Asokan, N},
  booktitle={2019 IEEE European Symposium on Security and Privacy (EuroS\&P)},
  pages={512--527},
  year={2019},
  organization={IEEE}
}

@article{orekondy2019prediction,
  title={Prediction poisoning: Towards defenses against dnn model stealing attacks},
  author={Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
  journal={arXiv preprint arXiv:1906.10908},
  year={2019}
}

@article{danka2018modal,
  title={modAL: A modular active learning framework for Python},
  author={Danka, Tivadar and Horvath, Peter},
  journal={arXiv preprint arXiv:1805.00979},
  year={2018}
}

@article{houlsby2011bayesian,
  title={Bayesian active learning for classification and preference learning},
  author={Houlsby, Neil and Husz{\'a}r, Ferenc and Ghahramani, Zoubin and Lengyel, M{\'a}t{\'e}},
  journal={arXiv preprint arXiv:1112.5745},
  year={2011}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@inproceedings{aljundi2018memory,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={139--154},
  year={2018}
}

@inproceedings{park2019continual,
  title={Continual learning by asymmetric loss approximation with single-side overestimation},
  author={Park, Dongmin and Hong, Seokil and Han, Bohyung and Lee, Kyoung Mu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3335--3344},
  year={2019}
}

@article{lee2017overcoming,
  title={Overcoming catastrophic forgetting by incremental moment matching},
  author={Lee, Sang-Woo and Kim, Jin-Hwa and Jun, Jaehyun and Ha, Jung-Woo and Zhang, Byoung-Tak},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ash2019deep,
  title={Deep batch active learning by diverse, uncertain gradient lower bounds},
  author={Ash, Jordan T and Zhang, Chicheng and Krishnamurthy, Akshay and Langford, John and Agarwal, Alekh},
  journal={arXiv preprint arXiv:1906.03671},
  year={2019}
}

@article{ren2021survey,
  title={A survey of deep active learning},
  author={Ren, Pengzhen and Xiao, Yun and Chang, Xiaojun and Huang, Po-Yao and Li, Zhihui and Gupta, Brij B and Chen, Xiaojiang and Wang, Xin},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={9},
  pages={1--40},
  year={2021},
  publisher={ACM New York, NY}
}

@article{lewis1994sequential,
  author    = {David D. Lewis and
               William A. Gale},
  title     = {A Sequential Algorithm for Training Text Classifiers},
  journal   = {CoRR},
  volume    = {abs/cmp-lg/9407020},
  year      = {1994},
  url       = {http://arxiv.org/abs/cmp-lg/9407020},
  eprinttype = {arXiv},
  eprint    = {cmp-lg/9407020},
  timestamp = {Mon, 13 Aug 2018 16:47:16 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LewisG94.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}

@article{gepperth2016bio,
  title={A bio-inspired incremental learning architecture for applied perceptual problems},
  author={Gepperth, Alexander and Karaoguz, Cem},
  journal={Cognitive Computation},
  volume={8},
  number={5},
  pages={924--934},
  year={2016},
  publisher={Springer}
}

//First reference of catastrophic forgetting
@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

//Synaptic intelligence paper and reference for three categories of continual learning
@inproceedings{zenke2017continual,
  title={Continual learning through synaptic intelligence},
  author={Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={3987--3995},
  year={2017},
  organization={PMLR}
}

// Hinton Knowledge distillation paper (used for functional regularization approaches in related work)
@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

// Learning without forgetting used as an example of functional regularization in related work section
@article{li2017learning,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2935--2947},
  year={2017},
  publisher={IEEE}
}

// Used as an example of functional regularization in related work section
@inproceedings{rannen2017encoder,
  title={Encoder based lifelong learning},
  author={Rannen, Amal and Aljundi, Rahaf and Blaschko, Matthew B and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1320--1328},
  year={2017}
}

// Resnet paper as an example for deep learning breakthroughs
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

// GAN paper as an example of deep learning breakthroughs
@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

// Backprop paper as an example of deep learning breakthroughs
@article{lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

// Example of how training data can be stolen
@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

// Example of how architecture of model can be stolen
@article{oh2019towards,
  title={Towards reverse-engineering black-box neural networks},
  author={Oh, Seong Joon and Schiele, Bernt and Fritz, Mario},
  journal={Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},
  pages={121--144},
  year={2019},
  publisher={Springer}
}

// Model stealing example
@inproceedings{tramer2016stealing,
  title={Stealing Machine Learning Models via Prediction APIs.},
  author={Tram{\`e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas},
  booktitle={USENIX security symposium},
  volume={16},
  pages={601--618},
  year={2016}
}

// Model stealing example
@inproceedings{papernot2017practical,
  title={Practical black-box attacks against machine learning},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  booktitle={Proceedings of the 2017 ACM on Asia conference on computer and communications security},
  pages={506--519},
  year={2017}
}

// Model stealing example
@inproceedings{reith2019efficiently,
  title={Efficiently stealing your machine learning models},
  author={Reith, Robert Nikolai and Schneider, Thomas and Tkachenko, Oleksandr},
  booktitle={Proceedings of the 18th ACM workshop on privacy in the electronic society},
  pages={198--210},
  year={2019}
}

// Model stealing defense example
@article{orekondy2019prediction,
  title={Prediction poisoning: Towards defenses against dnn model stealing attacks},
  author={Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
  journal={arXiv preprint arXiv:1906.10908},
  year={2019}
}

// PRADA as one example of a model stealing defence attack
@inproceedings{juuti2019prada,
  title={PRADA: protecting against DNN model stealing attacks},
  author={Juuti, Mika and Szyller, Sebastian and Marchal, Samuel and Asokan, N},
  booktitle={2019 IEEE European Symposium on Security and Privacy (EuroS\&P)},
  pages={512--527},
  year={2019},
  organization={IEEE}
}

// AGEM paper
@article{chaudhry2018efficient,
  title={Efficient lifelong learning with a-gem},
  author={Chaudhry, Arslan and Ranzato, Marc'Aurelio and Rohrbach, Marcus and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:1812.00420},
  year={2018}
}

// VAAL paper
@inproceedings{sinha2019variational,
  title={Variational adversarial active learning},
  author={Sinha, Samarth and Ebrahimi, Sayna and Darrell, Trevor},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5972--5981},
  year={2019}
}

// Active Learning Literature Survey
@article{settles2009active,
  title={Active learning literature survey},
  author={Settles, Burr},
  year={2009},
  publisher={University of Wisconsin-Madison Department of Computer Sciences}
}

// Example of early work on Query Synthesis Active Learning
@article{angluin1988queries,
  title={Queries and concept learning},
  author={Angluin, Dana},
  journal={Machine learning},
  volume={2},
  pages={319--342},
  year={1988},
  publisher={Springer}
}

// Query Synthesis with GAN
@article{zhu2017generative,
  title={Generative adversarial active learning},
  author={Zhu, Jia-Jie and Bento, Jos{\'e}},
  journal={arXiv preprint arXiv:1702.07956},
  year={2017}
}

// Example for Query Synthesis Active Learning with Regression
@article{cohn1996active,
  title={Active learning with statistical models},
  author={Cohn, David A and Ghahramani, Zoubin and Jordan, Michael I},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={129--145},
  year={1996}
}

// Example of problems using QS Active Learning when using a human oracle
@inproceedings{baum1992query,
  title={Query learning can work poorly when a human oracle is used},
  author={Baum, Eric B and Lang, Kenneth},
  booktitle={International joint conference on neural networks},
  volume={8},
  pages={8},
  year={1992},
  organization={Beijing China}
}

// First paper mentioning stream-based active learning
@article{cohn1994improving,
  title={Improving generalization with active learning},
  author={Cohn, David and Atlas, Les and Ladner, Richard},
  journal={Machine learning},
  volume={15},
  pages={201--221},
  year={1994},
  publisher={Springer}
}

// Example for stream-based AL based on informativeness of a query
@incollection{dagan1995committee,
  title={Committee-based sampling for training probabilistic classifiers},
  author={Dagan, Ido and Engelson, Sean P},
  booktitle={Machine Learning Proceedings 1995},
  pages={150--157},
  year={1995},
  publisher={Elsevier}
}

// First discovery of catastrophic forgetting
@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

// Stability vs plasticity dilemma
@article{carpenter1988art,
  title={The ART of adaptive pattern recognition by a self-organizing neural network},
  author={Carpenter, Gail A. and Grossberg, Stephen},
  journal={Computer},
  volume={21},
  number={3},
  pages={77--88},
  year={1988},
  publisher={IEEE}
}

// Example of Continual Learning Taxonomy
@article{van2018generative,
  title={Generative replay with feedback connections as a general strategy for continual learning},
  author={Van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1809.10635},
  year={2018}
}

// Paper about continual learning taxonomy
@article{van2022three,
  author          = {van de Ven, G.M., Tuytelaars, T. & Tolias, A.S.},
  journal         = {Nature Machine Intelligence},
  number          = {4},
  title           = {Three Types of incremental learning},
  pages           = {1185-1197},
  year            = {2022}
}

// review paper for continual learning (introduces taxonomy)
@article{parisi2019continual,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural networks},
  volume={113},
  pages={54--71},
  year={2019},
  publisher={Elsevier}
}
