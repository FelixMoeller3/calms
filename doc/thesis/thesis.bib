// TODO: Remove the sources that were in the template
@inproceedings{chandrasekaran2020exploring,
  title={Exploring connections between active learning and model extraction},
  author={Chandrasekaran, Varun and Chaudhuri, Kamalika and Giacomelli, Irene and Jha, Somesh and Yan, Songbai},
  booktitle={29th USENIX Security Symposium (USENIX Security 20)},
  pages={1309--1326},
  year={2020}
}

@inproceedings{pal2020activethief,
  title={Activethief: Model extraction using active learning and unannotated public data},
  author={Pal, Soham and Gupta, Yash and Shukla, Aditya and Kanade, Aditya and Shevade, Shirish and Ganapathy, Vinod},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={01},
  pages={865--872},
  year={2020}
}

@article{sener2017active,
  title={Active learning for convolutional neural networks: A core-set approach},
  author={Sener, Ozan and Savarese, Silvio},
  journal={arXiv preprint arXiv:1708.00489},
  year={2017}
}

@inproceedings{kim2021task,
  title={Task-aware variational adversarial active learning},
  author={Kim, Kwanyoung and Park, Dongwon and Kim, Kwang In and Chun, Se Young},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8166--8175},
  year={2021}
}

@article{mundt2020wholistic,
  title={A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning},
  author={Mundt, Martin and Hong, Yong Won and Pliushch, Iuliia and Ramesh, Visvanathan},
  journal={arXiv preprint arXiv:2009.01797},
  year={2020}
}

@article{danka2018modal,
  title={modAL: A modular active learning framework for Python},
  author={Danka, Tivadar and Horvath, Peter},
  journal={arXiv preprint arXiv:1805.00979},
  year={2018}
}

@article{houlsby2011bayesian,
  title={Bayesian active learning for classification and preference learning},
  author={Houlsby, Neil and Husz{\'a}r, Ferenc and Ghahramani, Zoubin and Lengyel, M{\'a}t{\'e}},
  journal={arXiv preprint arXiv:1112.5745},
  year={2011}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@inproceedings{aljundi2018memory,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={139--154},
  year={2018}
}

@inproceedings{park2019continual,
  title={Continual learning by asymmetric loss approximation with single-side overestimation},
  author={Park, Dongmin and Hong, Seokil and Han, Bohyung and Lee, Kyoung Mu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3335--3344},
  year={2019}
}

@article{lee2017overcoming,
  title={Overcoming catastrophic forgetting by incremental moment matching},
  author={Lee, Sang-Woo and Kim, Jin-Hwa and Jun, Jaehyun and Ha, Jung-Woo and Zhang, Byoung-Tak},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ash2019deep,
  title={Deep batch active learning by diverse, uncertain gradient lower bounds},
  author={Ash, Jordan T and Zhang, Chicheng and Krishnamurthy, Akshay and Langford, John and Agarwal, Alekh},
  journal={arXiv preprint arXiv:1906.03671},
  year={2019}
}

@article{ren2021survey,
  title={A survey of deep active learning},
  author={Ren, Pengzhen and Xiao, Yun and Chang, Xiaojun and Huang, Po-Yao and Li, Zhihui and Gupta, Brij B and Chen, Xiaojiang and Wang, Xin},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={9},
  pages={1--40},
  year={2021},
  publisher={ACM New York, NY}
}

@article{lewis1994sequential,
  author    = {David D. Lewis and
               William A. Gale},
  title     = {A Sequential Algorithm for Training Text Classifiers},
  journal   = {CoRR},
  volume    = {abs/cmp-lg/9407020},
  year      = {1994},
  url       = {http://arxiv.org/abs/cmp-lg/9407020},
  eprinttype = {arXiv},
  eprint    = {cmp-lg/9407020},
  timestamp = {Mon, 13 Aug 2018 16:47:16 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LewisG94.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}

@article{gepperth2016bio,
  title={A bio-inspired incremental learning architecture for applied perceptual problems},
  author={Gepperth, Alexander and Karaoguz, Cem},
  journal={Cognitive Computation},
  volume={8},
  number={5},
  pages={924--934},
  year={2016},
  publisher={Springer}
}

//First reference of catastrophic forgetting
@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

//Synaptic intelligence paper and reference for three categories of continual learning
@inproceedings{zenke2017continual,
  title={Continual learning through synaptic intelligence},
  author={Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={3987--3995},
  year={2017},
  organization={PMLR}
}

// Hinton Knowledge distillation paper (used for functional regularization approaches in related work)
@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

// Learning without forgetting used as an example of functional regularization in related work section
@article{li2017learning,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2935--2947},
  year={2017},
  publisher={IEEE}
}

// Used as an example of functional regularization in related work section
@inproceedings{rannen2017encoder,
  title={Encoder based lifelong learning},
  author={Rannen, Amal and Aljundi, Rahaf and Blaschko, Matthew B and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1320--1328},
  year={2017}
}

// Resnet paper as an example for deep learning breakthroughs
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

// GAN paper as an example of deep learning breakthroughs
@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

// Backprop paper as an example of deep learning breakthroughs
@article{lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

// Example of how training data can be stolen
@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

// Example of how architecture of model can be stolen
@article{oh2019towards,
  title={Towards reverse-engineering black-box neural networks},
  author={Oh, Seong Joon and Schiele, Bernt and Fritz, Mario},
  journal={Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},
  pages={121--144},
  year={2019},
  publisher={Springer}
}

// Model stealing example
@inproceedings{tramer2016stealing,
  title={Stealing Machine Learning Models via Prediction APIs.},
  author={Tram{\`e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas},
  booktitle={USENIX security symposium},
  volume={16},
  pages={601--618},
  year={2016}
}

// Model stealing example
@inproceedings{papernot2017practical,
  title={Practical black-box attacks against machine learning},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  booktitle={Proceedings of the 2017 ACM on Asia conference on computer and communications security},
  pages={506--519},
  year={2017}
}

// Model stealing example
@inproceedings{reith2019efficiently,
  title={Efficiently stealing your machine learning models},
  author={Reith, Robert Nikolai and Schneider, Thomas and Tkachenko, Oleksandr},
  booktitle={Proceedings of the 18th ACM workshop on privacy in the electronic society},
  pages={198--210},
  year={2019}
}

// Model stealing defense example
@article{orekondy2019prediction,
  title={Prediction poisoning: Towards defenses against dnn model stealing attacks},
  author={Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
  journal={arXiv preprint arXiv:1906.10908},
  year={2019}
}

// PRADA as one example of a model stealing defence attack
@inproceedings{juuti2019prada,
  title={PRADA: protecting against DNN model stealing attacks},
  author={Juuti, Mika and Szyller, Sebastian and Marchal, Samuel and Asokan, N},
  booktitle={2019 IEEE European Symposium on Security and Privacy (EuroS\&P)},
  pages={512--527},
  year={2019},
  organization={IEEE}
}

// AGEM paper
@article{chaudhry2018efficient,
  title={Efficient lifelong learning with a-gem},
  author={Chaudhry, Arslan and Ranzato, Marc'Aurelio and Rohrbach, Marcus and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:1812.00420},
  year={2018}
}

// VAAL paper
@inproceedings{sinha2019variational,
  title={Variational adversarial active learning},
  author={Sinha, Samarth and Ebrahimi, Sayna and Darrell, Trevor},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5972--5981},
  year={2019}
}

// Active Learning Literature Survey
@article{settles2009active,
  title={Active learning literature survey},
  author={Settles, Burr},
  year={2009},
  publisher={University of Wisconsin-Madison Department of Computer Sciences}
}

// Example of early work on Query Synthesis Active Learning
@article{angluin1988queries,
  title={Queries and concept learning},
  author={Angluin, Dana},
  journal={Machine learning},
  volume={2},
  pages={319--342},
  year={1988},
  publisher={Springer}
}

// Query Synthesis with GAN
@article{zhu2017generative,
  title={Generative adversarial active learning},
  author={Zhu, Jia-Jie and Bento, Jos{\'e}},
  journal={arXiv preprint arXiv:1702.07956},
  year={2017}
}

// Example for Query Synthesis Active Learning with Regression
@article{cohn1996active,
  title={Active learning with statistical models},
  author={Cohn, David A and Ghahramani, Zoubin and Jordan, Michael I},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={129--145},
  year={1996}
}

// Example of problems using QS Active Learning when using a human oracle
@inproceedings{baum1992query,
  title={Query learning can work poorly when a human oracle is used},
  author={Baum, Eric B and Lang, Kenneth},
  booktitle={International joint conference on neural networks},
  volume={8},
  pages={8},
  year={1992},
  organization={Beijing China}
}

// First paper mentioning stream-based active learning
@article{cohn1994improving,
  title={Improving generalization with active learning},
  author={Cohn, David and Atlas, Les and Ladner, Richard},
  journal={Machine learning},
  volume={15},
  pages={201--221},
  year={1994},
  publisher={Springer}
}

// Example for stream-based AL based on informativeness of a query
@incollection{dagan1995committee,
  title={Committee-based sampling for training probabilistic classifiers},
  author={Dagan, Ido and Engelson, Sean P},
  booktitle={Machine Learning Proceedings 1995},
  pages={150--157},
  year={1995},
  publisher={Elsevier}
}

// First discovery of catastrophic forgetting
@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

// Stability vs plasticity dilemma
@article{carpenter1988art,
  title={The ART of adaptive pattern recognition by a self-organizing neural network},
  author={Carpenter, Gail A. and Grossberg, Stephen},
  journal={Computer},
  volume={21},
  number={3},
  pages={77--88},
  year={1988},
  publisher={IEEE}
}

// Example of Continual Learning Taxonomy
@article{van2018generative,
  title={Generative replay with feedback connections as a general strategy for continual learning},
  author={Van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1809.10635},
  year={2018}
}

// Paper about continual learning taxonomy
@article{van2022three,
  author          = {Gido van de Ven, Tinne Tuytelaars \& Andreas S. Tolias},
  journal         = {Nature Machine Intelligence},
  number          = {4},
  title           = {Three Types of incremental learning},
  pages           = {1185-1197},
  year            = {2022}
}

// review paper for continual learning (introduces taxonomy)
@article{parisi2019continual,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural networks},
  volume={113},
  pages={54--71},
  year={2019},
  publisher={Elsevier}
}

// Survey paper for model stealing
@article{oliynyk2022know,
  title={I Know What You Trained Last Summer: A Survey on Stealing Machine Learning Models and Defences},
  author={Oliynyk, Daryna and Mayer, Rudolf and Rauber, Andreas},
  journal={arXiv preprint arXiv:2206.08451},
  year={2022}
}

// Knock-off nets paper
@inproceedings{orekondy2019knockoff,
  title={Knockoff nets: Stealing functionality of black-box models},
  author={Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4954--4963},
  year={2019}
}

// equation-solving approach to extract hyperparameters during training
@inproceedings{wang2018stealing,
  title={Stealing hyperparameters in machine learning},
  author={Wang, Binghui and Gong, Neil Zhenqiang},
  booktitle={2018 IEEE symposium on security and privacy (SP)},
  pages={36--52},
  year={2018},
  organization={IEEE}
}

// Meta-model approach to predict hyperparameters
@article{oh2019towards,
  title={Towards reverse-engineering black-box neural networks},
  author={Oh, Seong Joon and Schiele, Bernt and Fritz, Mario},
  journal={Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},
  pages={121--144},
  year={2019},
  publisher={Springer}
}

// example of side channel attacks to extract DNN model architecture
@inproceedings{yan2020cache,
  title={Cache telepathy: Leveraging shared resource attacks to learn DNN architectures},
  author={Yan, Mengjia and Fletcher, Christopher and Torrellas, Josep},
  booktitle={USENIX Security Symposium},
  year={2020}
}

// extracting the weights of a binary classifier
@inproceedings{lowd2005adversarial,
  title={Adversarial learning},
  author={Lowd, Daniel and Meek, Christopher},
  booktitle={Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining},
  pages={641--647},
  year={2005}
}

// extracting the weights for support vector regression
@inproceedings{reith2019efficiently,
  title={Efficiently stealing your machine learning models},
  author={Reith, Robert Nikolai and Schneider, Thomas and Tkachenko, Oleksandr},
  booktitle={Proceedings of the 18th ACM Workshop on Privacy in the Electronic Society},
  pages={198--210},
  year={2019}
}

// Example of model watermarking after training
@inproceedings{szyller2021dawn,
  title={Dawn: Dynamic adversarial watermarking of neural networks},
  author={Szyller, Sebastian and Atli, Buse Gul and Marchal, Samuel and Asokan, N},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={4417--4425},
  year={2021}
}

// Example of model watermarking during training
@inproceedings{zhang2018protecting,
  title={Protecting intellectual property of deep neural networks with watermarking},
  author={Zhang, Jialong and Gu, Zhongshu and Jang, Jiyong and Wu, Hui and Stoecklin, Marc Ph and Huang, Heqing and Molloy, Ian},
  booktitle={Proceedings of the 2018 on Asia Conference on Computer and Communications Security},
  pages={159--172},
  year={2018}
}

// Model stealing defense for Decision Trees (checks how much of the data space has been covered)
@inproceedings{kesarwani2018model,
  title={Model extraction warning in mlaas paradigm},
  author={Kesarwani, Manish and Mukhoty, Bhaskar and Arya, Vijay and Mehta, Sameep},
  booktitle={Proceedings of the 34th Annual Computer Security Applications Conference},
  pages={371--380},
  year={2018}
}

// Model stealing defense where multiple models are trained and their output is chosen randomly
@inproceedings{alabdulmohsin2014adding,
  title={Adding robustness to support vector machines against adversarial reverse engineering},
  author={Alabdulmohsin, Ibrahim M and Gao, Xin and Zhang, Xiangliang},
  booktitle={Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
  pages={231--240},
  year={2014}
}

// Example for model stealing defense by re-training from scratch.
@inproceedings{atli2020extraction,
  title={Extraction of complex dnn models: Real threat or boogeyman?},
  author={Atli, Buse Gul and Szyller, Sebastian and Juuti, Mika and Marchal, Samuel and Asokan, N},
  booktitle={Engineering Dependable and Secure Machine Learning Systems: Third International Workshop, EDSMLS 2020, New York City, NY, USA, February 7, 2020, Revised Selected Papers 3},
  pages={42--57},
  year={2020},
  organization={Springer}
}

// Model stealing defense via input perturbation
@inproceedings{guiga2020neural,
  title={Neural Network Security: Hiding CNN Parameters with Guided Grad-CAM.},
  author={Guiga, Linda and Roscoe, AW},
  booktitle={ICISSP},
  pages={611--618},
  year={2020}
}

// Model stealing defense via output perturbation (label flipping)
@inproceedings{shi2017evasion,
  title={Evasion and causative attacks with adversarial deep learning},
  author={Shi, Yi and Sagduyu, Yalin E},
  booktitle={MILCOM 2017-2017 IEEE Military Communications Conference (MILCOM)},
  pages={243--248},
  year={2017},
  organization={IEEE}
}

// Model stealing defense using differential privacy
@inproceedings{zheng2019bdpl,
  title={Bdpl: A boundary differentially private layer against machine learning model extraction attacks},
  author={Zheng, Huadi and Ye, Qingqing and Hu, Haibo and Fang, Chengfang and Shi, Jie},
  booktitle={Computer Security--ESORICS 2019: 24th European Symposium on Research in Computer Security, Luxembourg, September 23--27, 2019, Proceedings, Part I 24},
  pages={66--83},
  year={2019},
  organization={Springer}
}

// Model stealing defense by adding redundant layers
@article{chabanne2020protection,
  title={A protection against the extraction of neural network models},
  author={Chabanne, Herv{\'e} and Despiegel, Vincent and Guiga, Linda},
  journal={arXiv preprint arXiv:2005.12782},
  year={2020}
}

// Model stealing defense by using knowledge distillation
@article{xu2018deepobfuscation,
  title={Deepobfuscation: Securing the structure of convolutional neural networks via knowledge distillation},
  author={Xu, Hui and Su, Yuxin and Zhao, Zirui and Zhou, Yangfan and Lyu, Michael R and King, Irwin},
  journal={arXiv preprint arXiv:1806.10313},
  year={2018}
}

// Model stealing defense by increasing NN sensitivity
@inproceedings{szentannai2020preventing,
  title={Preventing Neural Network Weight Stealing via Network Obfuscation},
  author={Szentannai, K{\'a}lm{\'a}n and Al-Afandi, Jalal and Horv{\'a}th, Andr{\'a}s},
  booktitle={Intelligent Computing: Proceedings of the 2020 Computing Conference, Volume 3},
  pages={1--11},
  year={2020},
  organization={Springer}
}

// k-Center problem used for CoreSet
@misc{wolf2011facility,
  title={Facility location: concepts, models, algorithms and case studies.},
  author={Wolf, Gert W},
  year={2011},
  publisher={Taylor \& Francis}
}

// Shannon's entropy
@article{cover1991information,
  title={Information theory and statistics},
  author={Cover, Thomas M and Thomas, Joy A},
  journal={Elements of information theory},
  volume={1},
  number={1},
  pages={279--335},
  year={1991},
  publisher={Wiley New York}
}

// Monte Carlo Dropout
@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}

// Example of active learning using gradients
@inproceedings{zhang2017active,
  title={Active discriminative text representation learning},
  author={Zhang, Ye and Lease, Matthew and Wallace, Byron},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={31},
  number={1},
  year={2017}
}

// Example of active learning using gradients
@article{settles2007multiple,
  title={Multiple-instance active learning},
  author={Settles, Burr and Craven, Mark and Ray, Soumya},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}

// k-means++ paper cited for Badge
@inproceedings{arthur2007k,
  title={K-means++ the advantages of careful seeding},
  author={Arthur, David and Vassilvitskii, Sergei},
  booktitle={Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms},
  pages={1027--1035},
  year={2007}
}

// Book on information theory
@book{mackay2003information,
  title={Information theory, inference and learning algorithms, chapter 27: Laplace's method},
  author={MacKay, David JC and Mac Kay, David JC},
  year={2003},
  publisher={Cambridge university press}
}

// Deep dive into the statistics behind Elastic Weight Consolidation
@article{aich2021elastic,
  author       = {Abhishek Aich},
  title        = {Elastic Weight Consolidation (EWC): Nuts and Bolts},
  journal      = {CoRR},
  volume       = {abs/2105.04093},
  year         = {2021},
  url          = {https://arxiv.org/abs/2105.04093},
  eprinttype    = {arXiv},
  eprint       = {2105.04093},
  timestamp    = {Fri, 14 May 2021 12:13:30 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2105-04093.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

// Used for IMM paper explanation
@article{goldberger2004hierarchical,
  title={Hierarchical clustering of a mixture model},
  author={Goldberger, Jacob and Roweis, Sam},
  journal={Advances in neural information processing systems},
  volume={17},
  year={2004}
}

// Extracting a shallow network for text classification using active learning. Cited by ActiveThief
@inproceedings{shi2018active,
  title={Active deep learning attacks under strict rate limitations for online API calls},
  author={Shi, Yi and Sagduyu, Yalin E and Davaslioglu, Kemal and Li, Jason H},
  booktitle={2018 IEEE International Symposium on Technologies for Homeland Security (HST)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

// Deep-Fool based AL of Ducoffe and Precioso
@article{ducoffe2018adversarial,
  title={Adversarial active learning for deep networks: a margin based approach},
  author={Ducoffe, Melanie and Precioso, Frederic},
  journal={arXiv preprint arXiv:1802.09841},
  year={2018}
}

// AlexNet paper
@article{krizhevsky2017imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}

// Densenet Paper
@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

// Paper with special initialization of and some other insights on Active Learning
@article{beck2021effective,
  title={Effective evaluation of deep active learning on image classification tasks},
  author={Beck, Nathan and Sivasubramanian, Durga and Dani, Apurva and Ramakrishnan, Ganesh and Iyer, Rishabh},
  journal={arXiv preprint arXiv:2106.15324},
  year={2021}
}

// Paper which shows that task-ordering has a detrimental effect on continual learning performance
@article{bell2022effect,
  title={The Effect of Task Ordering in Continual Learning},
  author={Bell, Samuel J and Lawrence, Neil D},
  journal={arXiv preprint arXiv:2205.13323},
  year={2022}
}

// Paper that shows that training samples in difficulty order results in faster learning and improved generalization error.
@inproceedings{hacohen2019power,
  title={On the power of curriculum learning in training deep networks},
  author={Hacohen, Guy and Weinshall, Daphna},
  booktitle={International Conference on Machine Learning},
  pages={2535--2544},
  year={2019},
  organization={PMLR}
}
