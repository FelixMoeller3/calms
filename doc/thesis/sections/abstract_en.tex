%% LaTeX2e class for student theses
%% sections/abstract_en.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.6, 2022-09-28
\Abstract
The advancement of Machine Learning and especially Deep Learning has paved the way for remarkable breakthroughs in the Computer Vision domain \cite{he2016deep}
\cite{goodfellow2020generative} \cite{lecun1989backpropagation}. Despite its benefits, Deep Learning is a resource-intensive task because the architecture
of state-of-the-art models is becoming increasingly complex and these models need to be trained on vast amounts of labeled data. Big-tech companies like Google,
Amazon and Microsoft however have access to a lot of computing power which they monetize by offering \gls{mlaas}. \gls{mlaas}-Platforms
allow customers to train their models in the cloud and make them publicly accessible via prediction \glspl{api}. While \gls{mlaas} makes Machine Learning more
attainable it also poses a security risk. Previous works have shown that it is possible to infer numerous properties (e.g, training data \cite{shokri2017membership}
and architecture \cite{oh2019towards}) of the target model, i.e. the model behind the prediction \gls{api} \cite{tramer2016stealing}
\cite{papernot2017practical}. However, we purely focus on stealing the \textit{functionality} of the target model, i.e. its ability to predict the correct class
of a given input image. Because stealing Machine Learning models is such a pressing issue, there has been ongoing research on how to defend against Model Stealing
attacks \cite{orekondy2019prediction} \cite{juuti2019prada}. Surprisingly, recent research has shown that not all the proposed defenses are effective.
ActiveThief \cite{pal2020activethief}, a Model Extraction framework proposed by Pal et al. demonstrated state-of-the-art performance when stealing \glspl{dnn}.
They use active learning strategies to determine which samples to query the target model for and evade the \gls{prada} \cite{juuti2019prada} defense strategy. \par
The contribution of this thesis is two-fold. First, we combine Continual Learning and Active learning to see if we can improve the trade-off between accuracy and 
efficiency in the active learning process. Second, we incorporate the combination of Continual Learning and Active learning into the ActiveThief framework and
investigate whether our findings from the classic Active Learning process are transferable to the Model Stealing domain.
