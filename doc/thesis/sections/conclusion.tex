%% LaTeX2e class for student theses
%% sections/conclusion.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.6, 2022-09-28

\chapter{Conclusion}
\label{ch:Conclusion}
% Mention drops in accuracy due to Continual Active Learning. Regarding model stealing
% mention that there are cases where the CAL works a lot better than for normal continual
% active learning. Mention correlation with batch size to support the thesis that CAL fails
% because batch size is not large enough. Mention small difference between different active
% learning approaches for CIFAR-10 at least, which are inline with the findings from Yilins
% paper.
% Don't use data augmentation for model stealing!!!
This is the conclusion of the thesis.
\section{Conclusion for Continual Active Learning}
\label{sec:Conclusion:ContinualActiveLearning}

\section{Conclusion for Model Stealing}
\label{sec:Conclusion:ModelStealing}

\section{Future Work}
\label{sec:Conclusion:FutureWork}
% Future work could be to use the same approach in other types of continual learning settings,
% i.e. task-incremental settings, or class-incremental settings 
% Another approach is to use data distillation for replay to minimize the data overhead of active learning
% One could also use different Active Learning and Continual Learning approaches to see if the results are similar
% Another way is to combine the Active Learning and Continual Learning approaches, i.e. to combine the gradients used
% in AGEM for the selection by gradients using Badge
% Look if CAL is relevant to any security problem like e.g. malware analysis