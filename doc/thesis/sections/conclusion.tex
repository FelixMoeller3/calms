%% LaTeX2e class for student theses
%% sections/conclusion.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.6, 2022-09-28

\chapter{Conclusion}
\label{ch:Conclusion}
% Mention drops in accuracy due to Continual Active Learning. Regarding model stealing
% mention that there are cases where the CAL works a lot better than for normal continual
% active learning. Mention correlation with batch size to support the thesis that CAL fails
% because batch size is not large enough. Mention small difference between different active
% learning approaches for CIFAR-10 at least, which are inline with the findings from Yilins
% paper.
In this thesis, we proposed a novel approach named continual active learning, which combines active learning and continual learning. 
We implement multiple active learning strategies, namely \gls{bald}, \gls{lc}, \gls{badge} as well as CoreSet, and combine them with
the regularization-based continual learning strategies \gls{ewc}, \gls{imm}, \gls{alasso} and \gls{mas}, to create continual active
learning strategies. Next, we evaluate them on the dataset CIFAR-10 and the neural network architecture ResNet18. Our results demonstrate
that continual active learning strategies have significantly lower runtime than their active learning counterparts, but fail to achieve
their accuracy. Therefore, we decide to implement the active learning strategy \gls{vaal} along with the continual learning strategy \gls{a-gem}
to see if they can outperform the other continual active learning strategies but receive similar results. Our analysis of the results
suggests continual active learning achieves sub-par validation accuracy because the number of training points used in each active
learning iteration is too small. Further analysis of the results from our experiments with a custom Replay strategy support this theory. \par
Before applying continual active learning to the model stealing domain, we rigorously analyze the setting of the ActiveThief paper
\cite{pal2020activethief}. While we agree with most findings of the paper, we find that the architecture of the target and the substitute
model has a greater influence on the Model Agreement achieved than the authors of ActiveThief suggest. Furthermore, we find that the
choice of the thief dataset significantly influences model agreement, and so does using data augmentation on the thief dataset. \par
Finally, we perform model stealing attacks with continual active learning, using MNIST, CIFAR-10, and CIFAR-100 as target model datasets.
The results from these experiments closely resemble those from the classic continual active learning setting, i.e., we find that continual
active learning achieves lower model agreement than model extraction using active learning. \par
In general, we find that our approach is (resource-) \textit{efficient} but not \textit{effective} because it is significantly outperformed
by the baseline, both in the classic continual active learning and in the model stealing setting, in terms of accuracy and agreement,
respectively. However, we point out that the validity of our results is limited. First, the list of continual and active Learning
strategies we evaluated is not exhaustive, although we made every effort to include the most popular strategies. Second, we only evaluated our
approach with one neural network architecture and one dataset in the classic continual active learning setting and one Neural Network
plus three datasets in the model stealing setting.
\section{Future Work}
\label{sec:Conclusion:FutureWork}
% Future work could be to use the same approach in other types of continual learning settings,
% i.e. task-incremental settings, or class-incremental settings 
% Another approach is to use data distillation for replay to minimize the data overhead of active learning
% One could also use different Active Learning and Continual Learning approaches to see if the results are similar
% Another way is to combine the Active Learning and Continual Learning approaches, i.e. to combine the gradients used
% in AGEM for the selection by gradients using Badge
% Look if CAL is relevant to any security problem like e.g. malware analysis
The approach we proposed in this thesis is not limited to the settings we evaluated it in. While the most straightforward extension would
be to evaluate the method on new datasets and neural network architectures, we believe that, from a research
perspective, it would be more interesting to apply continual active learning to unrelated settings. In our methodology, we had an active-learning
-centric view on continual active learning, i.e., our main goal was to improve the accuracy of active learning while reducing its runtime. Future
work might be interested in approaching continual active learning from a continual learning perspective, for example, by using active learning to
perform task ordering in a task-incremental setting. Another idea could be to leverage the information of active learning for continual learning
and vice-versa. In our current framework, active learning and continual learning work independently, and we see potential for improvement by 
introducing interdependence between them. \par
Broadly speaking, our approach can be used in any setting where the data distribution of the task changes and labeling data is expensive.
In the computer security domain, our approach may be applied to malware analysis. Previous work has demonstrated the effectiveness of using
machine learning for malware analysis \parencite{nath2014static,ijaz2019static}. Malware analysis is well suited for our approach
because the features that classify malware change over time, and determining if a given piece of software contains malware is time-consuming.